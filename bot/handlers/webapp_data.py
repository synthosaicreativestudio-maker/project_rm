import json
import asyncio
import logging
from aiogram import Router, F, types
import google.generativeai as genai

from config.settings import settings

router = Router()
logger = logging.getLogger(__name__)

# Configure Gemini
if settings.GEMINI_API_KEY:
    genai.configure(api_key=settings.GEMINI_API_KEY)

@router.message(F.web_app_data)
async def handle_web_app_data(message: types.Message):
    """
    Handles data received from the Mini App via tg.sendData()
    """
    try:
        # Parse JSON data from WebApp
        data = json.loads(message.web_app_data.data)
        
        action_type = data.get('type')
        prompt = data.get('prompt')
        params = data.get('params', {})

        print(f"DEBUG REBOOT: Processing WebApp data: {action_type} | {prompt[:50]}...")
        logger.info(f"Processing WebApp data: {action_type} | {prompt[:50]}...")

        if action_type == 'image':
            from services.gemini import gemini_service
            
            model_id = settings.MODELS['image']
            aspect_ratio = params.get('aspectRatio', '1:1')
            
            await message.answer(f"üé® –†–∏—Å—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ({aspect_ratio})...\n–ü—Ä–æ–º—Ç: <i>{prompt[:100]}</i>")
            
            # Generate image
            image_bytes = await gemini_service.generate_image(prompt, aspect_ratio=aspect_ratio)
            
            if image_bytes:
                from aiogram.types import BufferedInputFile
                photo_file = BufferedInputFile(image_bytes, filename="generated.png")
                await message.answer_photo(photo=photo_file, caption=f"‚ú® –ì–æ—Ç–æ–≤–æ! –ú–æ–¥–µ–ª—å: {model_id}")
            else:
                await message.answer("‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")

        elif action_type == 'reference':
            from services.gemini import gemini_service
            import aiohttp
            import io
            from PIL import Image
            
            main_prompt = data.get('mainPrompt', '')
            references = data.get('references', [])
            
            await message.answer("üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ã –∏ —Å–æ–∑–¥–∞—é –º–∞—Å—Ç–µ—Ä-–ø—Ä–æ–º–ø—Ç... –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ.")
            
            images = []
            async with aiohttp.ClientSession() as session:
                for ref in references:
                    if ref.get('url'):
                        try:
                            async with session.get(ref['url']) as resp:
                                if resp.status == 200:
                                    img_data = await resp.read()
                                    img = Image.open(io.BytesIO(img_data))
                                    images.append(img)
                        except Exception as e:
                            logger.error(f"Error downloading image {ref['url']}: {e}")

            if not images and not main_prompt:
                await message.answer("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.")
                return

            # 1. Synthesize Prompt
            synthesized_prompt = await gemini_service.synthesize_reference_prompt(main_prompt, references, images)
            
            if not synthesized_prompt:
                 await message.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤.")
                 return

            await message.answer(f"üìù –°—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω –ø—Ä–æ–º–ø—Ç:\n<i>{synthesized_prompt[:200]}...</i>\n\nüé® –ó–∞–ø—É—Å–∫–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é...")
            
            # 2. Generate Image
            aspect_ratio = params.get('aspectRatio', '9:16')
            image_bytes = await gemini_service.generate_image(synthesized_prompt, aspect_ratio=aspect_ratio)
            
            if image_bytes:
                from aiogram.types import BufferedInputFile
                photo_file = BufferedInputFile(image_bytes, filename="ref_generated.png")
                await message.answer_photo(photo=photo_file, caption=f"‚ú® –ì–æ—Ç–æ–≤–æ –ø–æ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞–º!\n–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: {aspect_ratio}")
            else:
                await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")

        elif action_type == 'video':
            from services.veo import veo_service
            
            model_id = settings.MODELS['video']
            await message.answer(f"üé• –ó–∞–ø—É—Å–∫–∞—é –≤–∏–¥–µ–æ-–≥–µ–Ω–µ—Ä–∞—Ü–∏—é (Veo)...\n–≠—Ç–æ –∑–∞–π–º–µ—Ç 1-2 –º–∏–Ω—É—Ç—ã. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ.")
            
            video_bytes = await veo_service.generate_video(prompt)
            
            if video_bytes:
                 from aiogram.types import BufferedInputFile
                 video_file = BufferedInputFile(video_bytes, filename="generated_video.mp4")
                 await message.answer_video(video=video_file, caption=f"üé¨ –í–∞—à–µ –≤–∏–¥–µ–æ –≥–æ—Ç–æ–≤–æ!\n–ü—Ä–æ–º—Ç: <i>{prompt[:50]}...</i>")
            else:
                 await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ. \n–í–æ–∑–º–æ–∂–Ω–æ, –≤—Ä–µ–º–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ API –∏–ª–∏ –ª–∏–º–∏—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–π.")

    except Exception as e:
        logger.error(f"Error in reboot webapp_data handler: {e}")
        await message.answer(f"‚ùå –°–∏—Å—Ç–µ–º–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
